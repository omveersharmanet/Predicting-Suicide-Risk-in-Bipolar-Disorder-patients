{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab2eb380-f6f4-41f6-8cd2-1e0aee30cc75",
   "metadata": {},
   "source": [
    "## Su vs non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21a5bf-0c40-4b49-ace7-86ac41df7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mp_funcs\n",
    "from mp_funcs import classifiers\n",
    "import plotly.express as px\n",
    "import itertools\n",
    "import plotly.graph_objects as go\n",
    "import csv\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import auc, RocCurveDisplay, roc_curve, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb52832e-b1e0-4f3b-b2c6-cd92654adf71",
   "metadata": {},
   "source": [
    "### Load Data and save result to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20858fc-c8b6-415b-b623-c7b42634ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.read_csv('samples.csv', index_col=0)\n",
    "countMatrix_df = pd.read_csv('countMatrix_include_gene_name_13_samples.csv', index_col=0).T\n",
    "df1_reset = countMatrix_df.reset_index(drop=True)\n",
    "df2_reset = samples_df.reset_index(drop=True)\n",
    "data = pd.concat([df1_reset, df2_reset], axis=1)\n",
    "#data.to_csv('data.csv',  index_label=True)\n",
    "data = data.groupby(by='patient').first()\n",
    "data['condition']= data['condition'].apply(lambda x: 1 if x == 'Suicidal' else 0)\n",
    "data.drop(columns=[ 'sex','age', 'batch','diagnosis'], inplace=True)\n",
    "condition=data['condition']\n",
    "condition_satisfied = data.iloc[:, :-1].loc[:, data.iloc[:, :-1].sum(axis=0) > 10]\n",
    "final_data = pd.concat([condition_satisfied, data.iloc[:, -1]], axis=1)\n",
    "#final_data.to_csv('final_data.csv',  index_label=True)\n",
    "data = final_data.copy()\n",
    "data['condition']=condition\n",
    "data.to_csv('data_filterred_minimum_10_count_13_samples.csv',  index_label='patient')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91da2a41-6b3e-4cd0-b866-79c4bcbaa558",
   "metadata": {},
   "source": [
    "# leave-one-out cross-validation (LOOCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7514a3-0639-4017-9cf8-5027c565002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_gene_min_p_value=50\n",
    "Top_genes_in_ith_iter=20\n",
    "number_of_genes_for_combination=10\n",
    "numFolds=50\n",
    "\n",
    "\n",
    "final_fearure_list_all=[]\n",
    "search_result_all=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d043d7-ebb9-4247-8881-8c3f95a5ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ith in range (1, 1+data.shape[0]):\n",
    "#for ith in range (1, 4):\n",
    "    df_without_ith_row = data.drop(ith)\n",
    "    # Calculate mann-whitney u-test for eact gene and keep p-value\n",
    "    stat_result = scipy.stats.mannwhitneyu(df_without_ith_row[df_without_ith_row['condition']==0] , df_without_ith_row[df_without_ith_row['condition']==1] )\n",
    "    # take the 50 genes with lowest p-value\n",
    "    min_pval_idx = np.argsort(stat_result[1])[:number_of_gene_min_p_value]\n",
    "    focus_features_list = list(df_without_ith_row.columns[min_pval_idx])\n",
    "    focus_features_list.remove('condition')\n",
    "    # make sure, condition is not part of features list\n",
    "    \n",
    "    \n",
    "    print('condition' in focus_features_list)\n",
    "    norm_count_df= data.iloc[:, min_pval_idx[:number_of_gene_min_p_value]].melt(id_vars='condition',  var_name='Genes')\n",
    "    norm_count_df['value']=np.log(norm_count_df['value'])\n",
    "\n",
    "\n",
    "    search_result=[]\n",
    "    pool = mp.Pool(processes=32)\n",
    "    for k, num_of_features in enumerate(range(1, number_of_genes_for_combination)): \n",
    "        #print(k)\n",
    "        for features in itertools.combinations(focus_features_list[:number_of_gene_min_p_value],num_of_features): \n",
    "        # print(features)\n",
    "            score_mp = pool.apply_async(mp_funcs.global_predicat, args=(df_without_ith_row, features,))\n",
    "            search_result.append({'num_of_features': num_of_features, 'features': features, \n",
    "                                  'score_mp': score_mp})\n",
    "\n",
    "    pool.close()\n",
    "    pool.join() \n",
    "    print('Done')\n",
    "\n",
    "    search_result_all.append(search_result)\n",
    "\n",
    "    df = pd.DataFrame(search_result)\n",
    "    df['score']=df['score_mp'].apply(lambda x: x.get())\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    groups_of_genes = df[(df['score']>0.95)]['features'].to_list()\n",
    "\n",
    "    final_fearure_list = [x[0] for x in Counter(list(sum(groups_of_genes, ()))).most_common(Top_genes_in_ith_iter)]\n",
    "    final_fearure_list_all.append(final_fearure_list)\n",
    "    #plt.plot([mp_funcs.global_predicat(df_without_ith_row, final_fearure_list[:x],) for x in range(1,Top_genes_in_ith_iter+1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044bbe7-8919-4a34-bb08-95ce5afe8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Flatten the list of lists\n",
    "all_names = [name for sublist in final_fearure_list_all for name in sublist]\n",
    "\n",
    "# Count occurrences of each name\n",
    "name_counts = Counter(all_names)\n",
    "\n",
    "# Get the 50 most common names\n",
    "most_common_names = name_counts.most_common(50)\n",
    "\n",
    "#print(\"50 most common names and their counts:\")\n",
    "#for name, count in most_common_names:\n",
    "    #print(name, \"-\", count)\n",
    "most_common_genes_list = [name for name, count in most_common_names]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d5a1b-7302-4397-8a69-3db0e55ec8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(most_common_genes_list[:20], columns=['Feature'])\n",
    "df.to_csv('most_common_50_genes_list_from_13_iteration.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0cd0e5-1225-4fe0-a210-733bda7ecfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[['condition'] + most_common_genes_list[:50]]\n",
    "stat_result = scipy.stats.mannwhitneyu(filtered_data[filtered_data['condition']==0] , filtered_data[filtered_data['condition']==1] )\n",
    "# take the 50 genes with lowest p-value\n",
    "min_pval_idx = np.argsort(stat_result[1])[:50]\n",
    "focus_features_list = list(filtered_data.columns[min_pval_idx])\n",
    "focus_features_list.remove('condition')\n",
    "\n",
    "'condition' in focus_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08f53d7-7778-4c2a-97fe-e45480d94583",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_count_df= filtered_data.iloc[:, min_pval_idx[:31]].melt(id_vars='condition',  var_name='Genes')\n",
    "norm_count_df['value']=np.log(norm_count_df['value']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0dddb-448e-4306-97ab-84d76533829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 20th genes with lowest p-value ...\n",
    "fig = px.strip(norm_count_df, x=\"Genes\", y=\"value\", color=\"condition\",\n",
    "                 title=\"\",\n",
    "                 labels={\"value\":\"Log-Count (Arb. unit)\"} # customize axis label\n",
    "                )\n",
    "\n",
    "fig.show()\n",
    "fig = px.bar(x=focus_features_list[:30], y=stat_result[1][min_pval_idx[1:31]], title='Lowest Mann-Whitney UTest p-value',  )\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Genes\",yaxis_title=\"P-Value\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238ee79-2d9c-41e5-889c-0a3bf91de48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fearure_list=most_common_genes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc860d6-71b5-4d0b-b8f7-e1474a12bc3d",
   "metadata": {},
   "source": [
    "## selecting 10 genes out of most 20 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fbd64-91f6-4347-bafc-f1cf3369e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result=[]\n",
    "pool = mp.Pool(processes=32)\n",
    "for k, num_of_features in enumerate(range(1, 10)): \n",
    "    #print(k)\n",
    "    for features in itertools.combinations(most_common_genes_list[:20],num_of_features): \n",
    "        # print(features)\n",
    "        score_mp = pool.apply_async(mp_funcs.global_predicat, args=(data, features,))\n",
    "        search_result.append({'num_of_features': num_of_features, 'features': features, \n",
    "                              'score_mp': score_mp})\n",
    "\n",
    "pool.close()\n",
    "pool.join() \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc968f7-2fa3-446f-be12-2d913be2aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot([mp_funcs.global_predicat(data, final_fearure_list[:x],) for x in range(1,11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7294539-3417-476a-8332-6bbb4a29f583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(search_result)\n",
    "df['score']=df['score_mp'].apply(lambda x: x.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbddc1-043d-4111-aeb4-8837c5f608b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "featVsScore =df.groupby('num_of_features')\n",
    "plt.errorbar(x=featVsScore['score'].mean().index, y=featVsScore['score'].mean(), yerr=featVsScore['score'].std().to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4926e3e-3af7-4a9d-8ead-58c1838d4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "groups_of_genes = df[(df['score']>0.95)]['features'].to_list()\n",
    "with open('SuicidevsNon_suicidal_20commonGeneList_for_ML.txt','w') as f: \n",
    "    f.writelines([x[0]+'\\n' for x in Counter(list(sum(groups_of_genes, ()))).most_common(20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a05021-d3c8-4148-922c-b380dd5e893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fearure_list=[x[0]+'\\n' for x in Counter(list(sum(groups_of_genes, ()))).most_common(20)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a620e-559e-418b-93b1-118502f1a09d",
   "metadata": {},
   "source": [
    "## ML training and testing on 13 samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e38f287-d907-4f14-bf12-34bc2ad1c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fearure_list=most_common_genes_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114554a-eeb2-4659-8927-ef587bf56efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresList = final_fearure_list[:1]\n",
    "scorePerClf={}\n",
    "for clf_name, clf in classifiers:\n",
    "    scorePerClf[clf_name]=[]\n",
    "numFolds=50\n",
    "\n",
    "ss = ShuffleSplit(n_splits=numFolds, train_size=0.50, random_state=None)\n",
    "for train_index, test_index in ss.split(df_without_ith_row):\n",
    "\n",
    "    \n",
    "    # train subbet\n",
    "    X_train = np.array(data.iloc[train_index,:].loc[:, featuresList])\n",
    "    y_train= np.array(data.iloc[train_index,:].loc[:,'condition'])      \n",
    "    \n",
    "    X_test = np.array(data.iloc[test_index,:].loc[:, featuresList])\n",
    "    y_test= np.array(data.iloc[test_index,:].loc[:,'condition'])\n",
    "    \n",
    "    for clf_name, clf in classifiers:\n",
    "        \n",
    "        pipe = Pipeline([  ('scaler', StandardScaler()),  ('clf', clf),  ])  \n",
    "        pipe.fit(X_train,y_train)\n",
    "        scorePerClf[clf_name].append(pipe.score(X_test,y_test))\n",
    "\n",
    "\n",
    "scorePerClf_df= pd.DataFrame(scorePerClf)\n",
    "scorePerClf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e30ee0-1da5-4c24-aaf8-80f0b8ffa74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_averages = scorePerClf_df.mean(axis=0)\n",
    "row_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeedde62-de0d-4ff3-99c4-b35723fa6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data_frame=scorePerClf_df.melt(value_vars=scorePerClf_df.columns, var_name='Classifier', value_name='Accuracy'), \n",
    "              y='Accuracy', x= 'Classifier', color='Classifier')\n",
    "fig.update_layout(yaxis_range=[0.5,1.05], height=600)\n",
    "#fig.write_image('Suicidal_Vs_Nonsuicida__Accuracy.eps')\n",
    "fig.show()\n",
    "for k,v in scorePerClf.items(): \n",
    "    print(f' {k}: {np.mean(v):.3f} ± {np.std(v):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493ba7fe-f253-48d8-873d-f1bda1fb63c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresList = final_fearure_list[:8]\n",
    "scorePerClf={}\n",
    "for clf_name, clf in classifiers:\n",
    "    scorePerClf[clf_name]=[]\n",
    "numFolds=50\n",
    "\n",
    "ss = ShuffleSplit(n_splits=numFolds, train_size=0.50, random_state=None)\n",
    "for train_index, test_index in ss.split(df_without_ith_row):\n",
    "\n",
    "    \n",
    "    # train subbet\n",
    "    X_train = np.array(data.iloc[train_index,:].loc[:, featuresList])\n",
    "    y_train= np.array(data.iloc[train_index,:].loc[:,'condition'])      \n",
    "    \n",
    "    X_test = np.array(data.iloc[test_index,:].loc[:, featuresList])\n",
    "    y_test= np.array(data.iloc[test_index,:].loc[:,'condition'])\n",
    "    \n",
    "    for clf_name, clf in classifiers:\n",
    "        \n",
    "        pipe = Pipeline([  ('scaler', StandardScaler()),  ('clf', clf),  ])  \n",
    "        pipe.fit(X_train,y_train)\n",
    "        scorePerClf[clf_name].append(pipe.score(X_test,y_test))\n",
    "\n",
    "\n",
    "scorePerClf_df= pd.DataFrame(scorePerClf)\n",
    "scorePerClf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854bcb9a-124e-4afe-b0ca-15ad2623e13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_averages = scorePerClf_df.mean(axis=0)\n",
    "row_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e33142-05ab-40ef-98b3-f89899181fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(data_frame=scorePerClf_df.melt(value_vars=scorePerClf_df.columns, var_name='Classifier', value_name='Accuracy'), \n",
    "              y='Accuracy', x= 'Classifier', color='Classifier')\n",
    "fig.update_layout(yaxis_range=[0.5,1.05], height=600)\n",
    "fig.write_image('Suicidal_Vs_Nonsuicida__Accuracy_for_8_features.png')\n",
    "#fig.write_image('Suicidal_Vs_Nonsuicida__Accuracy_for_8_features.eps')\n",
    "fig.show()\n",
    "for k,v in scorePerClf.items(): \n",
    "    print(f' {k}: {np.mean(v):.3f} ± {np.std(v):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fdaacd-42ff-4cec-a929-f0299b1545fd",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca4a59-a752-4bca-b05c-dd2c31cd5266",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresList = final_fearure_list[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b72dec-bf29-420f-9d7b-1358aaf320c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.loc[:, featuresList])\n",
    "y = np.array(data.loc[:,'condition'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c791ee1-60b8-4d9c-8e0c-22328c9f726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(classifier, numFolds=5, ax=None): \n",
    "    clf = classifier[1]\n",
    "    clf_label = classifier[0]\n",
    "   \n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    actual_condition = np.empty([0], dtype=int)\n",
    "    predicated_condition = np.empty([0], dtype=int)\n",
    "\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    cv = ShuffleSplit(n_splits=numFolds, train_size=0.5, random_state=1234).split(X,y)\n",
    "    if not ax: \n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    for fold, (train, test) in enumerate(cv):\n",
    "        clf.fit(X[train], y[train])\n",
    "        if isinstance(clf, SVC):\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(X[train])\n",
    "            X[train]=scaler.transform(X[train])\n",
    "            X[test]=scaler.transform(X[test])\n",
    "            \n",
    "            probas_ = clf.fit(X[train], y[train]).decision_function(X[test])\n",
    "            # Compute ROC curve and area the curve\n",
    "            fpr, tpr, thresholds = roc_curve(y[test], probas_)     \n",
    "            \n",
    "\n",
    "        else: \n",
    "            probas_ = clf.fit(X[train], y[train]).predict_proba(X[test])\n",
    "            # Compute ROC curve and area the curve\n",
    "            fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "            \n",
    "        predicated_condition = np.append(predicated_condition, clf.predict(X[test]))\n",
    "        actual_condition = np.append(actual_condition,y[test])\n",
    "        \n",
    "        interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(auc(fpr, tpr))\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", label=\"chance level (AUC = 0.5)\")\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm\\sigma$\",\n",
    "    )\n",
    "\n",
    "    ax.set(\n",
    "        xlim=[-0.05, 1.05],\n",
    "        ylim=[-0.05, 1.05],\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"{clf_label}\\nROC curve with cross-validation\",\n",
    "    )\n",
    "    ax.axis(\"square\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    # plt.show()\n",
    "    return ax, (mean_fpr, mean_tpr), (predicated_condition, actual_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1fa04-55d6-4e00-9bb7-0666146b62f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_confusion_matrix(actual_classes , predicted_classes , labels , ax):\n",
    "\n",
    "    matrix = confusion_matrix(actual_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure() #figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=labels, yticklabels=labels, cmap=\"Blues\", fmt=\"g\", ax=ax)\n",
    "    ax.set_xlabel('Predicted'); ax.set_ylabel('Actual'); \n",
    "    ax.title.set_text('Confusion Matrix')\n",
    "\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6a60c-7932-4b17-bad9-eaabbb65186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rocPerClf={}\n",
    "for classifier in classifiers[:]: \n",
    "    fig, axes = plt.subplots(1,2, figsize=(15,7))\n",
    "    _, rocPerClf[classifier[0]], (predicated_condition, actual_condition) = plot_ROC(classifier, ax = axes[0], numFolds=50)\n",
    "    plot_confusion_matrix(actual_condition , predicated_condition , labels=['Suicide', 'Non-Suicide'] , ax=axes[1])\n",
    "    fig.savefig(f'Suicidal_Vs_Nonsuicida_ROC_{classifier[0]}.png')\n",
    "    #fig.savefig(f'SuicidevsNon-suicide_ROC_{classifier[0]}.eps')\n",
    "    #fig.savefig(f'SuicidevsNon-suicide_ROC_{classifier[0]}.pdf')\n",
    "    # plt.show()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43abb47-be2c-431b-865c-11ba5d5546e0",
   "metadata": {},
   "source": [
    "### Joined ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7e1e71-ee38-4453-9830-2e432c887453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create traces\n",
    "fig = go.Figure()\n",
    "\n",
    "for k, v in rocPerClf.items(): \n",
    "    fig.add_trace(go.Scatter(x=v[0], y=v[1],\n",
    "                        mode='lines',\n",
    "                        name=k))\n",
    "    \n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1],\n",
    "                         line=dict(color='black', width=2,\n",
    "                              dash='dash'), \n",
    "                        mode='lines',name='chance level (AUC = 0.5)'))\n",
    "fig.update_layout(title='ROC mean value', width = 800, height= 600)\n",
    "#fig.savefig('Suicidal_Vs_Nonsuicida_ROC_All_classifier.png')\n",
    "fig.write_image('Suicidal_Vs_Nonsuicida_ROC_All_classifiers.png')\n",
    "#fig.write_image('LRvsLR_ROC.eps')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d292a83-f5ec-42ea-95b4-8eac3db7c155",
   "metadata": {},
   "source": [
    "# Testing on unklnown samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498df8dd-e6ef-475a-8494-bacf4bb237ee",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c47ea-d7a8-4d20-b6ec-b01e2a300d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_df = pd.read_csv('samples20sample.csv', index_col=0)\n",
    "countMatrix_df = pd.read_csv('countMatrix_include_gene_name20sample.csv', index_col=0).T\n",
    "df1_reset = countMatrix_df.reset_index(drop=True)\n",
    "df2_reset = samples_df.reset_index(drop=True)\n",
    "data = pd.concat([df1_reset, df2_reset], axis=1)\n",
    "#data.to_csv('data20samples.csv',  index_label=True)\n",
    "data = data.groupby(by='patient').first()\n",
    "data['condition']= data['condition'].apply(lambda x: 1 if x == 'Suicidal' else 0)\n",
    "data.drop(columns=[ 'sex','age', 'batch','diagnosis'], inplace=True)\n",
    "condition=data['condition']\n",
    "condition_satisfied = data.iloc[:, :-1].loc[:, data.iloc[:, :-1].sum(axis=0) > 10]\n",
    "final_data = pd.concat([condition_satisfied, data.iloc[:, -1]], axis=1)\n",
    "#final_data.to_csv('final_data20samples.csv',  index_label=True)\n",
    "data = final_data.copy()\n",
    "data['condition']=condition\n",
    "data.to_csv('data_filterred_minimum_10_count_20_samples.csv',  index_label='patient')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b37982-c838-4f27-aae6-3c5e218d4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresList = final_fearure_list[:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45df854-f7ad-4e35-acec-7c61694f1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index=[0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "test_index=[13,14,15,16,17,18,19]\n",
    "train_index,test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6727b2b2-e504-4df4-927e-2b34179ae017",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(data.iloc[train_index,:].loc[:, featuresList])\n",
    "y_train= np.array(data.iloc[train_index,:].loc[:,'condition'])\n",
    "X_test = np.array(data.iloc[test_index,:].loc[:, featuresList])\n",
    "y_test= np.array(data.iloc[test_index,:].loc[:,'condition'])\n",
    "\n",
    "X_train,y_train,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b706b8-24b9-49ae-8bdd-e14846bdea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#featuresList = final_fearure_list[:1]\n",
    "#print(featuresList )\n",
    "scorePerClf={}\n",
    "PredictionPerClf={}\n",
    "for clf_name, clf in classifiers:\n",
    "    scorePerClf[clf_name]=[]\n",
    "    PredictionPerClf[clf_name]=[]\n",
    "for i in range (1,10):\n",
    "    featuresList = final_fearure_list[:i]\n",
    "    X_train = np.array(data.iloc[train_index,:].loc[:, featuresList])\n",
    "    y_train= np.array(data.iloc[train_index,:].loc[:,'condition'])      \n",
    "    \n",
    "    X_test = np.array(data.iloc[test_index,:].loc[:, featuresList])\n",
    "    y_test= np.array(data.iloc[test_index,:].loc[:,'condition'])\n",
    "    \n",
    "    for clf_name, clf in classifiers:\n",
    "        \n",
    "        pipe = Pipeline([  ('scaler', StandardScaler()),  ('clf', clf),  ])  \n",
    "        pipe.fit(X_train,y_train)\n",
    "        scorePerClf[clf_name].append(pipe.score(X_test,y_test))\n",
    "        PredictionPerClf[clf_name].append(pipe.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5790b-bb00-4d53-934b-18020605b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name, clf in classifiers:\n",
    "        \n",
    "    a=torch.tensor(PredictionPerClf[clf_name]).T\n",
    "    file_name_last_etr_model=clf_name+str('_prediction')+str('.csv')\n",
    "    pd.DataFrame(torch.tensor(PredictionPerClf[clf_name]).T).to_csv( file_name_last_etr_model)\n",
    "    print(clf_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a045b06-9461-4b96-bcfa-c64e88d507d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scorePerClf={}\n",
    "PredictionPerClf={}\n",
    "for clf_name, clf in classifiers:\n",
    "    scorePerClf[clf_name]=[]\n",
    "    PredictionPerClf[clf_name]=[]\n",
    "i=8\n",
    "featuresList = final_fearure_list[:i]\n",
    "X_train = np.array(data.iloc[train_index,:].loc[:, featuresList])\n",
    "y_train= np.array(data.iloc[train_index,:].loc[:,'condition'])      \n",
    "    \n",
    "X_test = np.array(data.iloc[test_index,:].loc[:, featuresList])\n",
    "y_test= np.array(data.iloc[test_index,:].loc[:,'condition'])\n",
    "    \n",
    "for clf_name, clf in classifiers:\n",
    "        \n",
    "    pipe = Pipeline([  ('scaler', StandardScaler()),  ('clf', clf),  ])  \n",
    "    pipe.fit(X_train,y_train)\n",
    "    scorePerClf[clf_name].append(pipe.score(X_test,y_test))\n",
    "    PredictionPerClf[clf_name].append(pipe.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3269fa-d94d-4ff6-ba12-7101476b9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf_name, clf in classifiers:\n",
    "        \n",
    "    a=torch.tensor(PredictionPerClf[clf_name]).T\n",
    "    file_name_last_etr_model=clf_name+str('_prediction')+str('.csv')\n",
    "    pd.DataFrame(torch.tensor(PredictionPerClf[clf_name]).T).to_csv( file_name_last_etr_model)\n",
    "    print(clf_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf37f3-ad93-403f-8580-a623b0ffe786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
